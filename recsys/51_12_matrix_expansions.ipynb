{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings = pd.read_csv(\"ml-latest-small/ratings.csv\")\n",
    "df_movies = pd.read_csv(\"ml-latest-small/movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = df_ratings.pivot_table(index=['userId'], columns=['movieId'], values='rating')\n",
    "# Contruct a sparse matrix for our users and items containing number of plays\n",
    "sparse_ui= sp.csr_matrix(user_item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(sparse_ui, test_size = 0.25, random_state=57)\n",
    "ind_train, ind_test = train_test_split(user_item_matrix, test_size = 0.25, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res = pd.DataFrame(index=ind_train.index, data=[], columns=['actual'])\n",
    "for i in X_res.index:\n",
    "    X_res.loc[i]['actual'] = list(set(ind_train.loc[i][ind_train.loc[i].notnull()].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train_u = pd.Series(ind_train.index.tolist())\n",
    "ind_train_i = pd.Series(ind_train.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=57\n",
    "rstate = np.random.RandomState(seed)\n",
    "rank_size=10\n",
    "lambda_val = 0.1\n",
    "num_user = X_train.shape[0]\n",
    "num_item = X_train.shape[1]\n",
    "P = sparse.csr_matrix((rstate.normal(size = (num_user, rank_size)))) # Random numbers in a m x rank shape\n",
    "Q = sparse.csr_matrix((rstate.normal(size = (num_item, rank_size)))) # Normally this would be rank x n but we can transpose at the end. Makes calculation more simple.\n",
    "QTQ = Q.T.dot(Q) # QTQ\n",
    "PTP = P.T.dot(P)\n",
    "P_eye = sparse.eye(num_user)\n",
    "Q_eye = sparse.eye(num_item)\n",
    "lambda_eye = lambda_val * sparse.eye(rank_size) # Our regularization term lambda*I."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0044179  -0.01638758 -0.00766912 -0.00914071  0.02136258 -0.00095192\n",
      "  -0.00905147  0.01610489  0.00381576 -0.00747813]]\n"
     ]
    }
   ],
   "source": [
    "u=5\n",
    "pref = X_train[u, :].toarray() # Grab user row from confidence matrix and convert to dense\n",
    "pref_u = pref[~np.isnan(pref)] # We take only the movies which the user has rated\n",
    "u_rated_movies_ind = np.argwhere(~np.isnan(pref))[:,1] # Index of the rated movies\n",
    "Qu = Q[u_rated_movies_ind, :] # We construct the Qu matrix of only rated existant pairs (u, i)\n",
    "QuTru = Qu.T.dot(pref_u.T) # This is the QuTPu term\n",
    "Q[u] = spsolve(QTQ +lambda_eye, QuTru)\n",
    "print(Q[u].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lfm_als(training_set, lambda_val, iterations=10, rank_size=20, seed=57):\n",
    "    \"\"\"\n",
    "    Model by Bell R.M., Koren Y., Volinsky C. The BellKor 2008 solution to the Netflix Prize.\n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - Our matrix of ratings with shape m x n, where m is the number of users and n is the number of items.\n",
    "    Should be a sparse csr matrix to save space. \n",
    "    \n",
    "    lambda_val - Used for regularization during alternating least squares. Increasing this value may increase bias\n",
    "    but decrease variance. Default is 0.1. \n",
    "    \n",
    "    iterations - The number of times to alternate between both user feature vector and item feature vector in\n",
    "    alternating least squares. More iterations will allow better convergence at the cost of increased computation. \n",
    "    The authors found 10 iterations was sufficient, but more may be required to converge. \n",
    "    \n",
    "    rank_size - The number of latent features in the user/item feature vectors. The paper recommends varying this \n",
    "    between 20-200. Increasing the number of features may overfit but could reduce bias. \n",
    "    \n",
    "    seed - Set the seed for reproducible results\n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The feature vectors for users and items. The dot product of these feature vectors should give you the expected \n",
    "    \"rating\" at each point in your original matrix. \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the size of our original ratings matrix, m x n\n",
    "    num_user = training_set.shape[0]\n",
    "    num_item = training_set.shape[1]\n",
    "    \n",
    "    # initialize our X/Y feature vectors randomly with a set seed\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    \n",
    "    P = sparse.csr_matrix((rstate.normal(size = (num_user, rank_size)))) # предсставление пользователей\n",
    "    Q = sparse.csr_matrix((rstate.normal(size = (num_item, rank_size)))) # Normally this would be rank x n but we can transpose at the end. Makes calculation more simple.\n",
    "    QTQ = Q.T.dot(Q) # QTQ\n",
    "    PTP = P.T.dot(P)\n",
    "    P_eye = sparse.eye(num_user)\n",
    "    Q_eye = sparse.eye(num_item)\n",
    "    lambda_eye = lambda_val * sparse.eye(rank_size) # Our regularization term lambda*I.\n",
    "    \n",
    "    # Begin iterations\n",
    "   \n",
    "    # Iterate back and forth between solving X given fixed Y and vice versa\n",
    "    for iter_step in range(iterations):\n",
    "        # Compute yTy and xTx at beginning of each iteration to save computing time\n",
    "        QTQ = Q.T.dot(Q) # QTQ\n",
    "        PTP = P.T.dot(P)\n",
    "        \n",
    "        # Being iteration to solve for P based on fixed Q\n",
    "        for u in range(num_user):\n",
    "            pref = training_set[u, :].toarray() # Grab user row from confidence matrix and convert to dense\n",
    "            pref_u = pref[~np.isnan(pref)] # We take only the movies which the user has rated\n",
    "            u_rated_movies_ind = np.argwhere(~np.isnan(pref))[:,1] # Index of the rated movies\n",
    "            Qu = Q[u_rated_movies_ind, :] # We construct the Qu matrix of only rated existant pairs (u, i)\n",
    "            QuTru = Qu.T.dot(pref_u.T) # This is the QuTru term\n",
    "            Q[u] = spsolve(QTQ +lambda_eye, QuTru) # Solve for Qu = ((QTQ + lambda*I)^-1)QT*Pu | Ax=b\n",
    "        \n",
    "        # Begin iteration to solve for Q based on fixed P\n",
    "        for i in range(num_item):\n",
    "            pref = X_train[:,i].toarray()\n",
    "            pref_i = pref[~np.isnan(pref)]\n",
    "            i_rated_movies_ind = np.argwhere(~np.isnan(pref))[:,0]\n",
    "            Pi = P[i_rated_movies_ind, :]\n",
    "            PiTri = Pi.T.dot(pref_i.T)\n",
    "            P[u] = spsolve(PTP + lambda_eye, PiTri)\n",
    "            \n",
    "    # End iterations\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "P, Q = lfm_als(X_train, lambda_val = 0.1, iterations = 10, rank_size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P shape: (457, 20)\n",
      "Q shape: (20, 9724)\n"
     ]
    }
   ],
   "source": [
    "print(\"P shape: {}\".format(P.shape))\n",
    "print(\"Q shape: {}\".format(Q.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find similar movies \n",
    "movieId = 5615\n",
    "ind_i = ind_train_i[ind_train_i == movieId].index[0]\n",
    "\n",
    "# Get the item row\n",
    "qi = Q[:, ind_i].toarray()[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the similarity score between choseen movie and other movies\n",
    "# and select the top 10 most similar.\n",
    "scores = Q.T.dot(qi)\n",
    "top_10 = np.argsort(scores)[::-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3977, 6043, 6192, 6991, 5879, 4048, 4439, 7068, 1166, 9547],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Man Who Cried, The (2000)'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies[df_movies['movieId']==ind_train_i[6043]]['title'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>movies</th>\n",
       "      <th>score</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5615</td>\n",
       "      <td>Invincible (2001)</td>\n",
       "      <td>29.756241</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40723</td>\n",
       "      <td>Wolf Creek (2005)</td>\n",
       "      <td>21.278858</td>\n",
       "      <td>Crime|Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45499</td>\n",
       "      <td>X-Men: The Last Stand (2006)</td>\n",
       "      <td>19.570919</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68073</td>\n",
       "      <td>Pirate Radio (2009)</td>\n",
       "      <td>19.309013</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33437</td>\n",
       "      <td>Unleashed (Danny the Dog) (2005)</td>\n",
       "      <td>18.446562</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5772</td>\n",
       "      <td>My Dinner with André (1981)</td>\n",
       "      <td>18.351032</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6564</td>\n",
       "      <td>Lara Croft Tomb Raider: The Cradle of Life (2003)</td>\n",
       "      <td>18.269228</td>\n",
       "      <td>Action|Adventure|Comedy|Romance|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70015</td>\n",
       "      <td>Polytechnique (2009)</td>\n",
       "      <td>18.228665</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1547</td>\n",
       "      <td>Shiloh (1997)</td>\n",
       "      <td>17.807164</td>\n",
       "      <td>Children|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>173873</td>\n",
       "      <td>Gulliver's Travels (1996)</td>\n",
       "      <td>17.672585</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                             movies      score  \\\n",
       "0     5615                                  Invincible (2001)  29.756241   \n",
       "1    40723                                  Wolf Creek (2005)  21.278858   \n",
       "2    45499                       X-Men: The Last Stand (2006)  19.570919   \n",
       "3    68073                                Pirate Radio (2009)  19.309013   \n",
       "4    33437                   Unleashed (Danny the Dog) (2005)  18.446562   \n",
       "5     5772                        My Dinner with André (1981)  18.351032   \n",
       "6     6564  Lara Croft Tomb Raider: The Cradle of Life (2003)  18.269228   \n",
       "7    70015                               Polytechnique (2009)  18.228665   \n",
       "8     1547                                      Shiloh (1997)  17.807164   \n",
       "9   173873                          Gulliver's Travels (1996)  17.672585   \n",
       "\n",
       "                                     genres  \n",
       "0                                     Drama  \n",
       "1                     Crime|Horror|Thriller  \n",
       "2                    Action|Sci-Fi|Thriller  \n",
       "3                              Comedy|Drama  \n",
       "4               Action|Crime|Drama|Thriller  \n",
       "5                                     Drama  \n",
       "6  Action|Adventure|Comedy|Romance|Thriller  \n",
       "7                               Crime|Drama  \n",
       "8                            Children|Drama  \n",
       "9                Adventure|Children|Fantasy  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = []\n",
    "movies_genres = []\n",
    "movies_scores = []\n",
    "movies_ids = []\n",
    "\n",
    "# Get and print the actual artists names and scores\n",
    "for idx in top_10:\n",
    "    movies_ids.append(ind_train_i[idx])\n",
    "    movies.append(df_movies[df_movies['movieId']==ind_train_i[idx]]['title'].iloc[0])\n",
    "    movies_genres.append(df_movies[df_movies['movieId']==ind_train_i[idx]]['genres'].iloc[0])\n",
    "    movies_scores.append(scores[idx])\n",
    "\n",
    "similar = pd.DataFrame({'movieId': movies_ids, 'movies': movies, 'score': movies_scores, 'genres': movies_genres})\n",
    "similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_top_k(user_id, training_set, P, Q, df_movies, ind_train_i, k=10):\n",
    "    \"\"\"\n",
    "    Recommend items for a given user given a trained model\n",
    "    Args:\n",
    "        user_id (int): The id of the user we want to create recommendations for.\n",
    "        data_sparse (csr_matrix): Our original training data.\n",
    "        P (csr_matrix): Users embedding\n",
    "        Q (pandas.DataFrame): Item embedding\n",
    "        k (int): How many recommendations we want to return:\n",
    "    Returns:\n",
    "        recommendations (pandas.DataFrame): DataFrame with k movies and scores\n",
    "    \"\"\"\n",
    "  \n",
    "    # Get all interactions by the user\n",
    "    user_interactions = training_set[user_id,:].toarray()\n",
    "\n",
    "    # We don't want to recommend items the user has consumed. So let's\n",
    "    # set them all to 0 and the NaNs to 1.\n",
    "    user_interactions = np.where(~np.isnan(user_interactions), 0, user_interactions)\n",
    "    user_interactions = np.nan_to_num(user_interactions[0], nan=1)\n",
    "    \n",
    "    # This is where we calculate the recommendation by taking the \n",
    "    # dot-product of the user vectors with the item vectors.\n",
    "            \n",
    "    rec_vector = P[user_id,:].dot(Q).toarray()\n",
    "    \n",
    "    # Let's scale our scores between 0 and 1 to make it all easier to interpret.\n",
    "    min_max = MinMaxScaler()\n",
    "    rec_vector_scaled = min_max.fit_transform(rec_vector.reshape(-1,1))[:,0]\n",
    "    recommend_vector = user_interactions*rec_vector_scaled\n",
    "   \n",
    "    # Get all the movies indices in order of recommendations (descending) and\n",
    "    # select only the top \"k\" items.\n",
    "    item_idx = np.argsort(recommend_vector)[::-1][:k]\n",
    "\n",
    "    # Loop through our recommended movie indicies and look up the movie title\n",
    "    movies = []\n",
    "    movies_scores = []\n",
    "    movies_ids = []\n",
    "\n",
    "    # Get and print the actual movie names, IDs and scores\n",
    "    for idx in item_idx:\n",
    "        movies_ids.append(ind_train_i[idx])\n",
    "        movies.append(df_movies[df_movies['movieId']==ind_train_i[idx]]['title'].iloc[0])\n",
    "        movies_scores.append(recommend_vector[idx])\n",
    "\n",
    "    similar = pd.DataFrame({'movieId': movies_ids, 'title': movies, 'score': movies_scores})\n",
    "    \n",
    "    return similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                                              title     score\n",
      "0     5615                                  Invincible (2001)  1.000000\n",
      "1    93502                                  Ledge, The (2011)  0.994485\n",
      "2    89072                                  Stake Land (2010)  0.957493\n",
      "3     4334                                       Yi Yi (2000)  0.947172\n",
      "4     5570                              Thesis (Tesis) (1996)  0.934872\n",
      "5    26236  White Sun of the Desert, The (Beloe solntse pu...  0.932483\n",
      "6    80549                                      Easy A (2010)  0.931932\n",
      "7     4395  Big Deal on Madonna Street (I Soliti Ignoti) (...  0.926718\n",
      "8   144222                             Bros Before Hos (2013)  0.924318\n",
      "9     3790                                      Groove (2000)  0.922260\n"
     ]
    }
   ],
   "source": [
    "# Let's generate and print our recommendations\n",
    "user_id = 103\n",
    "recommendations = predict_top_k(user_id, X_train, P, Q, df_movies, ind_train_i, k=10)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
